{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7875f60",
   "metadata": {},
   "source": [
    "### here i am gooing to use the set of tool like search , news search and much more \n",
    "### my example for this chainwas take the two llm and for each llm i am gooing to attach the 3 to 4 tool in that llm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1134928b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#befine the llm \n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"gemma2-9b-it\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=60,\n",
    "    groq_api_key=\"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\",\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "llm.invoke([HumanMessage(content=\"hello how are you!\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fb254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before that we want to crete the new some of the tools\n",
    "import socket\n",
    "import requests\n",
    "def featch_ip() -> str:\n",
    "    \"\"\"Fetch the IP address of the meachine .\n",
    "    return:\n",
    "        return the ip of the meachine\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ip_address = requests.get(\"https://api.ipify.org\").text\n",
    "        return ip_address\n",
    "    except requests.RequestException:\n",
    "        return \"Unable to fetch IP address\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5717a6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([featch_ip])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08a3080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call = llm_with_tools.invoke([HumanMessage(content=f\"can i get the ip of my meachine\", name=\"Lance\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e448a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da98338e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b249e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the state \n",
    "\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "\n",
    "\n",
    "class Store_message(TypedDict):\n",
    "    \"\"\"State to store messages.\"\"\"\n",
    "\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    name: str | None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1548c9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the node and ediges\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "    \n",
    "def greeting_node(state: Store_message):\n",
    "    print(\"______greeting_node______\")\n",
    "    print(\"hello\")\n",
    "    return {\"messages\": state[\"messages\"]}\n",
    "\n",
    "def llm_with_tool_calling_node(state: Store_message):\n",
    "    print(\"______llm_with_tool_calling_node______\")\n",
    "    print(\"calling the tool\")\n",
    "    # call the llm with the tool\n",
    "    tool_call = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # add the tool call to the state\n",
    "    return {\"messages\": tool_call}\n",
    "\n",
    "\n",
    "#add nodes\n",
    "\n",
    "graph = StateGraph(Store_message)\n",
    "graph.add_node(\"greeting\",greeting_node)\n",
    "graph.add_node(\"tool_calling\",llm_with_tool_calling_node)\n",
    "\n",
    "#add simple ediges\n",
    "\n",
    "graph.add_edge(START, \"greeting\")\n",
    "graph.add_edge(\"greeting\",\"tool_calling\")\n",
    "graph.add_edge(\"tool_calling\",END)\n",
    "build = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e115193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import Client\n",
    "# client = Client(api_key=\"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\")\n",
    "# prompt = client.pull_prompt(\"rlm/rag-document-relevance\", include_model=True)\n",
    "\n",
    "build\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca870235",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = build.invoke({\"messages\": HumanMessage(content=\"give the ip of my meachine\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e84f768",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6c07dc",
   "metadata": {},
   "source": [
    "## create the chain using the tools with two models one for normal user and another one for basil user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36827d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the state \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa942ad",
   "metadata": {},
   "source": [
    "# ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab99ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the llm and llm2\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "# this llm1 is only for basil\n",
    "llm1 = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    groq_api_key=\"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\",\n",
    "    # other params...\n",
    ")\n",
    "\n",
    "#this llm for everyone\n",
    "llm2 = ChatGroq(\n",
    "    model=\"qwen-qwq-32b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=60,\n",
    "    groq_api_key=\"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\",\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0c0df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm1.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff939f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c2b7a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the bunch of tool for llm\n",
    "\n",
    "\n",
    "import socket\n",
    "# featch the ip address\n",
    "from typing import List\n",
    "import requests\n",
    "\n",
    "#only for basil \n",
    "def featch_ip(ip:str) -> str:\n",
    "    \"\"\"it only featch the ip address from the meachine to get the public ip\"\"\"\n",
    "    try:\n",
    "        ip_address = requests.get(\"https://api.ipify.org\").text\n",
    "        return ip_address\n",
    "    except requests.RequestException:\n",
    "        return \"Unable to fetch IP address\"\n",
    "\n",
    "\n",
    "#only for basil to get the what are the port are the localmeachine \n",
    "\n",
    "# def scanning_port(port_start:int,port_end:int)-> str:\n",
    "#     \"\"\"get the port details from the local meachine\n",
    "#     args:\n",
    "#     prot_start: staring number of port eg:4\n",
    "#     prot_end: ending number of port eg:90\n",
    "#     \"\"\"\n",
    "#     t_IP = gethostbyname(\"127.0.0.1\")\n",
    "#     values = []\n",
    "#     for i in range(50, 500):\n",
    "#       s = socket(port_start, port_end)\n",
    "      \n",
    "#       conn = s.connect_ex((t_IP, i))\n",
    "#       if(conn == 0) :\n",
    "#          print ('Port %d: OPEN' % (i,))\n",
    "#          values+=[f\"Port: OPEN' % {(i,)}\"]\n",
    "#       s.close()\n",
    "#     return values\n",
    "\n",
    "def scanning_port(port_start: int, port_end: int) -> List[str]:\n",
    "    \"\"\"\n",
    "    Scans a range of ports on localhost to check if they are open.\n",
    "\n",
    "    Args:\n",
    "        port_start (int): Starting port number.\n",
    "        port_end (int): Ending port number.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of open ports with messages.\n",
    "    \"\"\"\n",
    "    t_IP = socket.gethostbyname(\"127.0.0.1\")\n",
    "    open_ports = []\n",
    "\n",
    "    for port in range(port_start, port_end + 1):  # range should include end\n",
    "        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "        # s.settimeout(0.5)  # Add timeout to avoid hanging\n",
    "        conn = s.connect_ex((t_IP, port))\n",
    "        if conn == 0:\n",
    "            msg = f\"Port {port}: OPEN\"\n",
    "            print(msg)\n",
    "            open_ports.append(msg)\n",
    "        s.close()\n",
    "\n",
    "    return open_ports\n",
    "\n",
    "\n",
    "#for other user function\n",
    "#that only for addiciton and subraction\n",
    "\n",
    "def addiction(a:int, b:int)-> int:\n",
    "    \"\"\"this function was perform the addicion and give the output in int\n",
    "    args:\n",
    "    a: number eg:44\n",
    "    b: number eg:3\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "def subraction(a:int, b:int)-> int:\n",
    "    \"\"\"this function was perform the subraction and give the output in int\n",
    "    args:\n",
    "    a: number eg:44\n",
    "    b: number eg:3\n",
    "    \"\"\"\n",
    "    return a - b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96d26853",
   "metadata": {},
   "outputs": [],
   "source": [
    "#binindg the along with two llms\n",
    "\n",
    "llm1 = llm1.bind_tools([featch_ip,scanning_port])\n",
    "llm2 = llm2.bind_tools([addiction,subraction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e0bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm1.invoke([HumanMessage(content=\"what are the port are open in my meachine from 80 to 81 port!\")])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77c3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm1.invoke([HumanMessage(content=\"give my meachine ip address of 192.193.33.44\")])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df6c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm2.invoke([HumanMessage(content=\"hello\")])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3b4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = llm2.invoke([HumanMessage(content=\"hello\")])\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25670f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tools_condition_for_llm1(state: Multi_llm_state) -> Literal[\"tools1\", END]:\n",
    "    # some logic to decide if tools1 should run\n",
    "    # e.g. if a tool call is needed\n",
    "    if \"tool_call\" in str(state[\"messages\"][-1]):\n",
    "        return \"tools1\"\n",
    "    return END\n",
    "\n",
    "def tools_condition_for_llm2(state: Multi_llm_state) -> Literal[\"tools2\", END]:\n",
    "    if \"tool_call\" in str(state[\"messages\"][-1]):\n",
    "        return \"tools2\"\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2883c7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Literal  \n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "\n",
    "# sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with using search and performing arithmetic on a set of inputs. and also perfoem the tool exicuction \")\n",
    "# sys_msg = SystemMessage(content=\"\"\"\n",
    "# You are a helpful assistant.\n",
    "\n",
    "# - For general queries (such as greetings, questions about the economy, environment, sports, or casual conversation), respond directly and naturally using your own language capabilities. Do not call any tools for these types of queries. For example, if the user says \"hello\", you might respond with \"Hello! How can I assist you today?\"\n",
    "\n",
    "# - Only use tools when the user provides a request that clearly requires computation, arithmetic, or data processing based on input values. In those cases, respond by invoking the appropriate tool.\n",
    "\n",
    "# Your main goal is to provide a natural, conversational experience for general questions and reserve tool usage strictly for computation-related tasks.\n",
    "# \"\"\")\n",
    "\n",
    "\n",
    "sys_msg = SystemMessage(content=\"You are a helpful assistant tasked with performing arithmetic on a set of inputs.\")\n",
    "\n",
    "class Multi_llm_state(TypedDict):\n",
    "    \"\"\"State to store messages.\"\"\"\n",
    "\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    name: str | None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4fea53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '# define the node and condictionss\n",
    "\n",
    "\n",
    "# from IPython.display import Image, display\n",
    "# from langgraph.graph import StateGraph, START, END\n",
    "# from langgraph.prebuilt import ToolNode\n",
    "# from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# # condiiction ediges\n",
    "\n",
    "# def routing_based_on_names(state:Multi_llm_state)-> Literal[\"llm1\",\"llm2\"]:\n",
    "#     if state[\"name\"] == \"basil\":\n",
    "#         return \"llm1\"\n",
    "#     return \"llm2\"\n",
    "\n",
    "\n",
    "# #greeding card:\n",
    "\n",
    "# def greeting(state:Multi_llm_state):\n",
    "#     print(\"_____greeting_______\")\n",
    "#     print(f\"Hello {state[\"name\"]}\")\n",
    "#     return {\"messages\":state[\"messages\"], \"name\":state[\"name\"]}\n",
    "# graph = StateGraph(Multi_llm_state)\n",
    "# #define the nodes\n",
    "\n",
    "\n",
    "# # node for llm1 and llm2\n",
    "\n",
    "# def llm_1(state:Multi_llm_state):\n",
    "#     print(\"------llm1 for basil------\")\n",
    "#     return {\"messages\": llm1.invoke(state[\"messages\"])}\n",
    "\n",
    "# def llm_2(state:Multi_llm_state):\n",
    "#     print(\"------llm2 for other member------\")\n",
    "#     return {\"messages\": llm2.invoke(state[\"messages\"])}\n",
    "\n",
    "\n",
    "# #define the nodes\n",
    "# graph.add_node(\"greeting\",greeting)\n",
    "# graph.add_node(\"llm1\",llm_1)\n",
    "# graph.add_node(\"llm2\",llm_2)\n",
    "# graph.add_node(\"tools1\",ToolNode([featch_ip,scanning_port]))\n",
    "# graph.add_node(\"tools2\",ToolNode([addiction,subraction]))\n",
    "\n",
    "\n",
    "# #add the ediges and condiction ediges\n",
    "\n",
    "# graph.add_edge(START,\"greeting\")\n",
    "# graph.add_conditional_edges(\"greeting\",routing_based_on_names)\n",
    "# graph.add_conditional_edges(\"llm1\",tools_condition_for_llm1)\n",
    "# graph.add_conditional_edges(\"llm2\",tools_condition_for_llm2)\n",
    "# # graph.add_edge(\"tools1\", END)\n",
    "# # graph.add_edge(\"tools2\", END)\n",
    "\n",
    "# build = graph.compile()\n",
    "\n",
    "\n",
    "# define the node and condictionss\n",
    "\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "# condiiction ediges\n",
    "\n",
    "def routing_based_on_names(state:Multi_llm_state)-> Literal[\"llm1\",\"llm2\"]:\n",
    "    if state[\"name\"] == \"basil\":\n",
    "        return \"llm1\"\n",
    "    return \"llm2\"\n",
    "\n",
    "\n",
    "#greeding card:\n",
    "\n",
    "def greeting(state:Multi_llm_state):\n",
    "    print(\"_____greeting_______\")\n",
    "    print(f\"Hello {state[\"name\"]}\")\n",
    "    return {\"messages\":state[\"messages\"], \"name\":state[\"name\"]}\n",
    "graph = StateGraph(Multi_llm_state)\n",
    "#define the nodes\n",
    "\n",
    "\n",
    "# node for llm1 and llm2\n",
    "\n",
    "def llm_1(state:Multi_llm_state):\n",
    "    print(\"------llm1 for basil------\")\n",
    "    return {\"messages\": [llm1.invoke([sys_msg] + state[\"messages\"])]}\n",
    "\n",
    "def llm_2(state:Multi_llm_state):\n",
    "    print(\"------llm2 for other member------\")\n",
    "    return {\"messages\": llm2.invoke([sys_msg] + state[\"messages\"])}\n",
    "\n",
    "\n",
    "#define the nodes\n",
    "graph.add_node(\"greeting\",greeting)\n",
    "graph.add_node(\"llm1\",llm_1)\n",
    "graph.add_node(\"llm2\",llm_2)\n",
    "# graph.add_node(\"tools\",ToolNode([featch_ip,scanning_port]))\n",
    "graph.add_node(\"tools\",ToolNode([addiction,subraction]))\n",
    "\n",
    "\n",
    "#add the ediges and condiction ediges\n",
    "\n",
    "graph.add_edge(START,\"greeting\")\n",
    "graph.add_conditional_edges(\"greeting\",routing_based_on_names)\n",
    "# graph.add_conditional_edges(\"llm1\",tools_condition)\n",
    "graph.add_conditional_edges(\"llm2\",tools_condition)\n",
    "graph.add_edge(\"tools\", \"llm2\")\n",
    "# graph.add_edge(\"tools2\", \"llm2\")\n",
    "\n",
    "build = graph.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1672684",
   "metadata": {},
   "outputs": [],
   "source": [
    "build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdfabda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____greeting_______\n",
      "Hello basil\n",
      "------llm1 for basil------\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "You are a helpful assistant tasked with performing arithmetic on a set of inputs.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "give me an port scane for my meachine and port of 80 to port of 81\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  scanning_port (call_rxea)\n",
      " Call ID: call_rxea\n",
      "  Args:\n",
      "    port_start: 80\n",
      "    port_end: 81\n"
     ]
    }
   ],
   "source": [
    "messages = build.invoke({\"messages\": [sys_msg, HumanMessage(content=\"give me an port scane for my meachine and port of 80 to port of 81\")],\"name\":\"basil\"})\n",
    "for m in messages['messages']:\n",
    "    \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b60c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____greeting_______\n",
      "Hello suresh\n",
      "------llm2 for other member------\n",
      "------llm2 for other member------\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what was the addiciton of 33 and 33\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  addiction (call_ng6m)\n",
      " Call ID: call_ng6m\n",
      "  Args:\n",
      "    a: 33\n",
      "    b: 33\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: addiction\n",
      "\n",
      "66\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The addition of 33 and 33 is **66**.\n"
     ]
    }
   ],
   "source": [
    "messages = build.invoke({\"messages\": HumanMessage(content=\"what was the addiciton of 33 and 33\"),\"name\":\"suresh\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc490b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4377632",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = build.invoke({\"messages\": HumanMessage(content=\"hello how are you\"),\"name\":\"dhanesh\"})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
